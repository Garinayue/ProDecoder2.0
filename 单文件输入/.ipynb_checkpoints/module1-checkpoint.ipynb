{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明\n",
    "改进了时间复杂度，先统计有哪些不同的n-gram，再去统计频率，消除了重复统计的时间  \n",
    "此外，不同n-gram之间的分隔符变成\"####\"，而不是采用可能出现的\"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数，读取文件，获得所有的报文数据\n",
    "# 参数：file_name 文件名称\n",
    "# 返回值：所有报文构成的列表，列表每个元素代表一条报文\n",
    "def read_input(file_name):\n",
    "    # 打开文件，按行读取\n",
    "    file = open(file_name, 'r', encoding='utf-8')\n",
    "    lines = file.readlines()  # 按行读取文件内容\n",
    "    file.close()\n",
    "    # 去除换行符，构造返回结果列表\n",
    "    packets = []  # 存放所有报文\n",
    "    for line in lines:  # 遍历，去除换行符\n",
    "        packets.append(line.strip('\\n'))\n",
    "    return packets\n",
    "\n",
    "\n",
    "# 定义函数，由所有报文得到不同的n-grams，列表中不会出现相同的元素。目的是提升统计频率的时间效率\n",
    "# 参数：第一个参数为n，便于尝试不同的n值；第二个参数为packets，即待划分的报文数据列表\n",
    "# 返回值：所有不同的 n-grams 构成的列表\n",
    "def get_unique_ngrams(n, packets):\n",
    "    num = len(packets)  # 报文数目\n",
    "    unique_ngrams = []\n",
    "    for i in range(num):  # 遍历所有报文\n",
    "        message = packets[i]\n",
    "        length = len(message)  # 长度\n",
    "        repeat = length - n + 1  # 一条报文上的循环次数\n",
    "        for i in range(repeat):\n",
    "            if message[i:i+n] not in unique_ngrams:\n",
    "                unique_ngrams.append(message[i:i+n])  # 都存入ngrams列表中\n",
    "    return unique_ngrams\n",
    "\n",
    "\n",
    "# 定义函数，由所有报文得到n-grams，此处还未做频率的统计处理\n",
    "# 参数：第一个参数为n，便于尝试不同的n值；第二个参数为packets，即待划分的报文数据列表\n",
    "# 返回值：所有 n-grams 构成的列表\n",
    "def get_all_ngrams(n, packets):\n",
    "    num = len(packets)  # 报文数目\n",
    "    all_ngrams = []\n",
    "    for i in range(num):  # 遍历所有报文\n",
    "        message = packets[i]\n",
    "        length = len(message)  # 长度\n",
    "        repeat = length - n + 1  # 一条报文上的循环次数\n",
    "        for i in range(repeat):\n",
    "            all_ngrams.append(message[i:i+n])  # 都存入ngrams列表中\n",
    "    return all_ngrams\n",
    "\n",
    "\n",
    "# 定义函数，只保留频率排名靠前的一部分n-grams\n",
    "# 参数：第一个参数为 P ，代表保留频率和满足阈值的一部分n-grams；\n",
    "#       第二个参数为unique_ngrams，即所有不同的n-grams的列表(get_unique_ngrams的返回值)\n",
    "#       第三个参数为all_ngrams，即所有报文的n-grams的列表(get_all_ngrams的返回值)\n",
    "# 返回值：频率和为P的 n-grams 列表\n",
    "def get_allfreq_ngrams(P, unique_ngrams, all_ngrams):\n",
    "    # 统计n-grams总数\n",
    "    num1 = len(unique_ngrams)\n",
    "    num2 = len(all_ngrams)\n",
    "    print(\"所有不同的n-grams总数为：\", num1)\n",
    "    print(\"所有报文的n-grams总数为：\", num2)\n",
    "    # 先统计每种n-gram的出现频率，记录在字典中\n",
    "    ngrams_dict = {}  # 存放各个n-gram的频率信息，无序的\n",
    "    for i in unique_ngrams:  # 遍历n-grams，统计每个出现频率\n",
    "        ngrams_dict[i] = all_ngrams.count(i)/num2  # key为n-gram, value为出现的频率\n",
    "    # 对频率进行由大到小排序\n",
    "    ordered = sorted(ngrams_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    # 取出频率较高的一部分一部分\n",
    "    allfreq_ngrams = []\n",
    "    i = 0  # 当前取到第几个\n",
    "    sum_p = 0  # 频率和\n",
    "    while(sum_p < P):\n",
    "        sum_p += ordered[i][1]\n",
    "        allfreq_ngrams.append(ordered[i][0])\n",
    "        i += 1\n",
    "    return allfreq_ngrams\n",
    "\n",
    "\n",
    "# 定义函数，由所有报文得到n-grams，此处还未做频率的统计处理\n",
    "# 参数：第一个参数为n，便于尝试不同的n值；第二个参数为packets，即待划分的报文数据列表\n",
    "# 返回值：列表套列表，大列表中每个元素是一个小列表，小列表对应一条报文的n-grams\n",
    "def get_separate_ngrams(n, packets):\n",
    "    sep_ngrams = []  # 用于存放不同报文的n-grams列表的大列表\n",
    "    num = len(packets)\n",
    "    for i in range(num):\n",
    "        message = packets[i]\n",
    "        length = len(message)\n",
    "        message_ngrams = []  # 存储该报文n-grams的小列表\n",
    "        repeat = length - n + 1  # 循环次数\n",
    "        for j in range(repeat):\n",
    "            message_ngrams.append(message[j:j+n])  # 小列表\n",
    "        sep_ngrams.append(message_ngrams)  # 大列表\n",
    "    return sep_ngrams\n",
    "\n",
    "\n",
    "# 定义函数，每个报文只保留频率较高的n-grams\n",
    "# 参数：第一个参数为 freq_ngrams，频数排名靠前的n-grams列表，即函数get_freq_ngrams的返回结果\n",
    "#       第二个参数为 ngrams, 各个报文n-grams列表组成的列表，即函数get_separate_ngrams的返回结果，大列表套小列表形式\n",
    "# 返回值：列表套列表，大列表中每个元素是一个小列表，小列表对应一条报文的高频n-grams\n",
    "def get_sepfreq_ngrams(allfreq_ngrams, ngrams):\n",
    "    sepfreq_ngrams = []  # 用于存放不同报文的高频n-grams列表的大列表\n",
    "    num = len(ngrams)\n",
    "    for i in range(num):  # 遍历报文\n",
    "        message = ngrams[i]\n",
    "        message_freq_ngrams = []  # 该报文高频n-grams的小列表\n",
    "        for j in range(len(message)):\n",
    "            if message[j] in allfreq_ngrams:\n",
    "                message_freq_ngrams.append(message[j])  # 小列表\n",
    "        sepfreq_ngrams.append(message_freq_ngrams)  # 大列表\n",
    "    return sepfreq_ngrams\n",
    "\n",
    "\n",
    "# 定义函数，将每个报文的高频n-grams保存到文件中,同一报文中n-grams空格隔开，每个报文占一行，末尾加换行符\n",
    "# 参数：第一个参数 file_name为写入的txt文件名；第二个参数是写入的内容，即报文的高频n-grams列表组成的大列表\n",
    "def save_freq_file(file_name, content):\n",
    "    file = open(file_name, 'a')  # 打开文件，追加末尾\n",
    "    num = len(content)  # 报文数目\n",
    "    s = \"\"  # 所有报文的组合内容\n",
    "    for i in range(num):\n",
    "        message = content[i]  # 取出一条报文的n-grams列表\n",
    "        t = \"####\".join(message)  # 用-组合起来，得到一条报文的内容，一般报文里没有-这个符号\n",
    "        s = s + t + '\\n'  # 去除每行末尾追加换行符\n",
    "    file.write(s)  # 写入\n",
    "    file.close()  # 关闭文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功读取输入文件\n",
      "成功获得所有不同的n-grams的列表\n",
      "成功获得所有n-grams的小列表\n",
      "所有不同的n-grams总数为： 55983\n",
      "所有报文的n-grams总数为： 111237\n",
      "\n",
      "保留频率和为0.200000的n-grams，共保留39个\n",
      "保留的n-grams为：\n",
      " ['name', ' nam', 'ion ', 'on t', 'n ti', ' tim', 'time', 'birt', 'irth', 'ther', 'her ', 'er n', 'r na', 'atio', 'tion', 'comp', 'ompa', 'mpan', 'pany', 'any ', 'me19', 'ime1', 'nkin', 'scho', 'choo', 'hool', 'ool ', 'ol n', 'l na', 'id n', 'd nu', ' num', 'numb', 'umbe', 'mber', 'admi', 'dmis', 'miss', 'issi']\n",
      "\n",
      "成功获得各个报文的n-grams列表\n",
      "成功获得各个报文的高频n-grams列表\n",
      "成功保存各个报文的高频n-grams到文件中\n",
      "\n",
      "该模块运行时间： 147.24093866348267 秒\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    begin_time = time.time()  # 统计程序运行时间\n",
    "    \n",
    "    n = 4  # 初始化取值，n-gram中 n 的取值\n",
    "    P = 0.2  # 保留的频率和\n",
    "\n",
    "    packets = read_input(\"input.txt\")  # 读取文件，得到报文列表\n",
    "    print(\"成功读取输入文件\")\n",
    "\n",
    "    unique_ngrams = get_unique_ngrams(n, packets)  # 从输入文件中获得所有n-grams的列表\n",
    "    print(\"成功获得所有不同的n-grams的列表\")\n",
    "    \n",
    "    all_ngrams = get_all_ngrams(n, packets)  # 从输入文件中获得所有n-grams的列表\n",
    "    print(\"成功获得所有n-grams的小列表\")\n",
    "\n",
    "    allfreq_ngrams = get_allfreq_ngrams(P, unique_ngrams, all_ngrams)  # 排序，取出频率较高的一部分n-grams\n",
    "    ngrams_num = len(allfreq_ngrams)\n",
    "    print(\"\\n保留频率和为%f的n-grams，共保留%d个\" % (P, ngrams_num))\n",
    "    print(\"保留的n-grams为：\\n\", allfreq_ngrams)\n",
    "\n",
    "    sep_ngrams = get_separate_ngrams(n, packets)  # 从输入文件中获得n-grams的大列表套小列表的形式\n",
    "    print(\"\\n成功获得各个报文的n-grams列表\")\n",
    "\n",
    "    sepfreq_ngrams = get_sepfreq_ngrams(allfreq_ngrams, sep_ngrams)  # 保留每条报文中的高频n-grams\n",
    "    print(\"成功获得各个报文的高频n-grams列表\")\n",
    "\n",
    "    save_freq_file(\"freq_ngrams.txt\", sepfreq_ngrams)  # 保存报文的高频n-grams\n",
    "    print(\"成功保存各个报文的高频n-grams到文件中\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    run_time = end_time - begin_time\n",
    "    print ('\\n该模块运行时间：',run_time, '秒')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间的改进\n",
    "相比于class_multi中的运行时间，缩小了一半，而55983/111237正好约为0.5，理论得到证明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
